{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_keras_aug.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMIbEbC+iD0GZuUhGMJ4V9w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujs/cifar10/blob/master/cifar10_keras_aug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3malBJFdyqxh",
        "colab_type": "text"
      },
      "source": [
        "*   model3- Baseline + Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjImQUIny5xP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "6b4c4665-4b87-4a44-9f70-4ee04f2489ad"
      },
      "source": [
        "#Importing libraries\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import SGD\n",
        "from keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAiGmdtCy6Tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#importing data\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "#load data\n",
        "(x, y),(x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLGcz6y9zFXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1d06c42c-d475-4052-856d-cf47da5c61f9"
      },
      "source": [
        "#examine shape of data\n",
        "print (x.shape)\n",
        "print (x_test.shape)\n",
        "print (y.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICrJrbu4zFh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2be6f721-9743-4a0b-b18a-99d9edc92fda"
      },
      "source": [
        "#Splitting x,y data into train and validation data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap3VwIs0zFdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "#one-hot encode target values\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "\n",
        "#Rescaling images \n",
        "\n",
        "train_datagen = ImageDataGenerator (rescale = 1./255)\n",
        "val_datagen = ImageDataGenerator (rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator (rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(x_train, y_train,batch_size = 64)\n",
        "val_generator = val_datagen.flow(x_val, y_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaeWVNOIzFbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model):\n",
        "  #Instantiate model\n",
        "  model = model()\n",
        "\n",
        "  #fit model\n",
        "  steps = x_train.shape[0]/64\n",
        "  history = model.fit_generator(train_generator, steps_per_epoch = steps, epochs = 80, validation_data = val_generator)\n",
        "  model.save('cifar10_{}'.format(model))\n",
        "\n",
        "  #Plot loss\n",
        "  plt.subplot(211)\n",
        "  plt.title('cross-entropy loss')\n",
        "  plt.plot(history.history['loss'],color = 'blue', label = 'train')\n",
        "  plt.plot(history.history['val_loss'], color = 'red', label = 'validation')\n",
        "  plt.legend()\n",
        "\n",
        "  #plot accurcay\n",
        "  plt.subplot(212)\n",
        "  plt.title('accuracy')\n",
        "  plt.plot(history.history['acc'],color = 'blue', label = 'train')\n",
        "  plt.plot(history.history['val_acc'], color = 'red', label = 'validation')\n",
        "  plt.legend()\n",
        "\n",
        "  # evaluate model\n",
        "  _, acc = model.evaluate(val_generator, verbose=0)\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwOzLvlly6aT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db4452fa-e86b-4673-e6f1-16d2ae0b1be6"
      },
      "source": [
        "# model3- Baseline + Data Augmentation\n",
        "\n",
        "def model3():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation ='relu', kernel_initializer='he_uniform', padding = 'same', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#data augmentation\n",
        "train_datagen = ImageDataGenerator (rescale = 1./255, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True)\n",
        "train_generator = train_datagen.flow(x_train, y_train,batch_size = 64)\n",
        "\n",
        "\n",
        "#testing\n",
        "test_model(model3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Epoch 1/80\n",
            "625/625 [==============================] - 319s 510ms/step - loss: 1.8473 - acc: 0.3328 - val_loss: 1.6066 - val_acc: 0.4218\n",
            "Epoch 2/80\n",
            "625/625 [==============================] - 321s 514ms/step - loss: 1.5497 - acc: 0.4416 - val_loss: 1.4003 - val_acc: 0.4917\n",
            "Epoch 3/80\n",
            "625/625 [==============================] - 327s 523ms/step - loss: 1.4162 - acc: 0.4948 - val_loss: 1.2907 - val_acc: 0.5390\n",
            "Epoch 4/80\n",
            "625/625 [==============================] - 328s 524ms/step - loss: 1.3132 - acc: 0.5302 - val_loss: 1.1829 - val_acc: 0.5794\n",
            "Epoch 5/80\n",
            "625/625 [==============================] - 327s 523ms/step - loss: 1.2264 - acc: 0.5653 - val_loss: 1.1822 - val_acc: 0.5842\n",
            "Epoch 6/80\n",
            "625/625 [==============================] - 329s 526ms/step - loss: 1.1647 - acc: 0.5865 - val_loss: 1.0890 - val_acc: 0.6130\n",
            "Epoch 7/80\n",
            "625/625 [==============================] - 328s 525ms/step - loss: 1.1059 - acc: 0.6105 - val_loss: 1.0710 - val_acc: 0.6223\n",
            "Epoch 8/80\n",
            "625/625 [==============================] - 328s 524ms/step - loss: 1.0612 - acc: 0.6258 - val_loss: 0.9645 - val_acc: 0.6596\n",
            "Epoch 9/80\n",
            "625/625 [==============================] - 323s 516ms/step - loss: 1.0180 - acc: 0.6421 - val_loss: 0.9692 - val_acc: 0.6568\n",
            "Epoch 10/80\n",
            "625/625 [==============================] - 321s 513ms/step - loss: 0.9875 - acc: 0.6497 - val_loss: 0.9310 - val_acc: 0.6735\n",
            "Epoch 11/80\n",
            "625/625 [==============================] - 327s 524ms/step - loss: 0.9501 - acc: 0.6676 - val_loss: 0.8988 - val_acc: 0.6821\n",
            "Epoch 12/80\n",
            "625/625 [==============================] - 324s 518ms/step - loss: 0.9212 - acc: 0.6778 - val_loss: 0.9474 - val_acc: 0.6642\n",
            "Epoch 13/80\n",
            "625/625 [==============================] - 321s 514ms/step - loss: 0.8924 - acc: 0.6891 - val_loss: 0.8371 - val_acc: 0.7055\n",
            "Epoch 14/80\n",
            "625/625 [==============================] - 322s 514ms/step - loss: 0.8627 - acc: 0.6970 - val_loss: 0.8224 - val_acc: 0.7150\n",
            "Epoch 15/80\n",
            "625/625 [==============================] - 322s 516ms/step - loss: 0.8425 - acc: 0.7051 - val_loss: 0.8228 - val_acc: 0.7138\n",
            "Epoch 16/80\n",
            "625/625 [==============================] - 325s 520ms/step - loss: 0.8201 - acc: 0.7135 - val_loss: 0.7687 - val_acc: 0.7336\n",
            "Epoch 17/80\n",
            "625/625 [==============================] - 323s 517ms/step - loss: 0.7974 - acc: 0.7222 - val_loss: 0.7649 - val_acc: 0.7328\n",
            "Epoch 18/80\n",
            "625/625 [==============================] - 321s 514ms/step - loss: 0.7692 - acc: 0.7317 - val_loss: 0.7650 - val_acc: 0.7403\n",
            "Epoch 19/80\n",
            "625/625 [==============================] - 324s 519ms/step - loss: 0.7534 - acc: 0.7381 - val_loss: 0.8264 - val_acc: 0.7170\n",
            "Epoch 20/80\n",
            "625/625 [==============================] - 325s 520ms/step - loss: 0.7363 - acc: 0.7437 - val_loss: 0.7369 - val_acc: 0.7453\n",
            "Epoch 21/80\n",
            "625/625 [==============================] - 322s 515ms/step - loss: 0.7172 - acc: 0.7480 - val_loss: 0.7321 - val_acc: 0.7486\n",
            "Epoch 22/80\n",
            "625/625 [==============================] - 325s 519ms/step - loss: 0.7066 - acc: 0.7547 - val_loss: 0.7197 - val_acc: 0.7557\n",
            "Epoch 23/80\n",
            "625/625 [==============================] - 326s 521ms/step - loss: 0.6889 - acc: 0.7596 - val_loss: 0.7318 - val_acc: 0.7453\n",
            "Epoch 24/80\n",
            "625/625 [==============================] - 320s 513ms/step - loss: 0.6738 - acc: 0.7647 - val_loss: 0.7420 - val_acc: 0.7524\n",
            "Epoch 25/80\n",
            "625/625 [==============================] - 319s 510ms/step - loss: 0.6701 - acc: 0.7667 - val_loss: 0.6833 - val_acc: 0.7655\n",
            "Epoch 26/80\n",
            "625/625 [==============================] - 320s 513ms/step - loss: 0.6531 - acc: 0.7716 - val_loss: 0.6685 - val_acc: 0.7672\n",
            "Epoch 27/80\n",
            "625/625 [==============================] - 321s 514ms/step - loss: 0.6410 - acc: 0.7792 - val_loss: 0.6630 - val_acc: 0.7715\n",
            "Epoch 28/80\n",
            "625/625 [==============================] - 329s 526ms/step - loss: 0.6287 - acc: 0.7782 - val_loss: 0.7196 - val_acc: 0.7602\n",
            "Epoch 29/80\n",
            "625/625 [==============================] - 328s 525ms/step - loss: 0.6169 - acc: 0.7851 - val_loss: 0.6732 - val_acc: 0.7725\n",
            "Epoch 30/80\n",
            "625/625 [==============================] - 327s 523ms/step - loss: 0.6139 - acc: 0.7867 - val_loss: 0.6739 - val_acc: 0.7694\n",
            "Epoch 31/80\n",
            "625/625 [==============================] - 325s 521ms/step - loss: 0.5966 - acc: 0.7935 - val_loss: 0.6856 - val_acc: 0.7684\n",
            "Epoch 32/80\n",
            "625/625 [==============================] - 328s 525ms/step - loss: 0.5779 - acc: 0.8003 - val_loss: 0.6929 - val_acc: 0.7671\n",
            "Epoch 33/80\n",
            "625/625 [==============================] - 324s 519ms/step - loss: 0.5782 - acc: 0.7985 - val_loss: 0.6185 - val_acc: 0.7848\n",
            "Epoch 34/80\n",
            "625/625 [==============================] - 324s 518ms/step - loss: 0.5676 - acc: 0.8016 - val_loss: 0.6344 - val_acc: 0.7847\n",
            "Epoch 35/80\n",
            "625/625 [==============================] - 318s 509ms/step - loss: 0.5558 - acc: 0.8069 - val_loss: 0.6284 - val_acc: 0.7844\n",
            "Epoch 36/80\n",
            "625/625 [==============================] - 320s 512ms/step - loss: 0.5493 - acc: 0.8082 - val_loss: 0.6620 - val_acc: 0.7776\n",
            "Epoch 37/80\n",
            "625/625 [==============================] - 321s 513ms/step - loss: 0.5448 - acc: 0.8092 - val_loss: 0.6075 - val_acc: 0.7899\n",
            "Epoch 38/80\n",
            "625/625 [==============================] - 322s 515ms/step - loss: 0.5370 - acc: 0.8154 - val_loss: 0.6513 - val_acc: 0.7799\n",
            "Epoch 39/80\n",
            "625/625 [==============================] - 321s 514ms/step - loss: 0.5261 - acc: 0.8160 - val_loss: 0.5855 - val_acc: 0.7982\n",
            "Epoch 40/80\n",
            "625/625 [==============================] - 323s 517ms/step - loss: 0.5169 - acc: 0.8206 - val_loss: 0.6176 - val_acc: 0.7935\n",
            "Epoch 41/80\n",
            "625/625 [==============================] - 327s 523ms/step - loss: 0.5169 - acc: 0.8180 - val_loss: 0.6051 - val_acc: 0.7986\n",
            "Epoch 42/80\n",
            "625/625 [==============================] - 324s 518ms/step - loss: 0.5032 - acc: 0.8240 - val_loss: 0.5937 - val_acc: 0.7973\n",
            "Epoch 43/80\n",
            "625/625 [==============================] - 322s 516ms/step - loss: 0.4997 - acc: 0.8242 - val_loss: 0.6018 - val_acc: 0.7986\n",
            "Epoch 44/80\n",
            "625/625 [==============================] - 323s 516ms/step - loss: 0.4878 - acc: 0.8294 - val_loss: 0.5939 - val_acc: 0.8017\n",
            "Epoch 45/80\n",
            "394/625 [=================>............] - ETA: 1:52 - loss: 0.4844 - acc: 0.8311"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrmY1gwty6hI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}