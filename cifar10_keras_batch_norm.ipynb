{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_keras_batch_norm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoDtK4RznPZBCsWvUPq3e8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujs/cifar10/blob/master/cifar10_keras_batch_norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l29A4XWwy0v1",
        "colab_type": "text"
      },
      "source": [
        "*   model5- Baseline + Dropout + Data Augmentation + Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr4-kM6h4yrq",
        "colab_type": "code",
        "outputId": "d910bf84-f9c6-4956-ffb8-6cb65ad666ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 102kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 30.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 58.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc1\n",
            "    Uninstalling tensorflow-2.2.0rc1:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc1\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8lfi-EAy7t-",
        "colab_type": "code",
        "outputId": "e07f4bb1-a0eb-4122-f65a-c1915cd74885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "#Importing libraries\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import SGD\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2_BLmbmy71s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#importing data\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "#load data\n",
        "(x, y),(x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cv-Qwzry74v",
        "colab_type": "code",
        "outputId": "e901af8d-d6d9-4d86-96c9-0531e55eac5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#examine shape of data\n",
        "print (x.shape)\n",
        "print (x_test.shape)\n",
        "print (y.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U12R3anDy78C",
        "colab_type": "code",
        "outputId": "2d829a17-ff67-480f-ed4f-8da28b350674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Splitting x,y data into train and validation data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqNgI6_fzEYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "#one-hot encode target values\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "\n",
        "#Rescaling images \n",
        "\n",
        "train_datagen = ImageDataGenerator (rescale = 1./255)\n",
        "val_datagen = ImageDataGenerator (rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator (rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(x_train, y_train,batch_size = 64)\n",
        "val_generator = val_datagen.flow(x_val, y_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g89mrQrzEbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model):\n",
        "  #Instantiate model\n",
        "  model = model()\n",
        "\n",
        "  #fit model\n",
        "  steps = x_train.shape[0]/64\n",
        "  history = model.fit_generator(train_generator, steps_per_epoch = steps, epochs = 80, validation_data = val_generator)\n",
        "  model.save('cifar10_{}'.format(model))\n",
        "\n",
        "  #Plot loss\n",
        "  plt.subplot(211)\n",
        "  plt.title('cross-entropy loss')\n",
        "  plt.plot(history.history['loss'],color = 'blue', label = 'train')\n",
        "  plt.plot(history.history['val_loss'], color = 'red', label = 'validation')\n",
        "  plt.legend()\n",
        "\n",
        "  #plot accurcay\n",
        "  plt.subplot(212)\n",
        "  plt.title('accuracy')\n",
        "  plt.plot(history.history['acc'],color = 'blue', label = 'train')\n",
        "  plt.plot(history.history['val_acc'], color = 'red', label = 'validation')\n",
        "  plt.legend()\n",
        "\n",
        "  # evaluate model\n",
        "  _, acc = model.evaluate(val_generator, verbose=0)\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCISGySJ6Wr9",
        "colab_type": "code",
        "outputId": "dff5643e-fe92-4e3e-e5a8-711c8b75fa13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model5- Baseline + Dropout + Data Augmentation + Batch Normalization\n",
        "def model5():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation ='relu', kernel_initializer='he_uniform', padding = 'same', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding = 'same'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#data augmentation\n",
        "train_datagen = ImageDataGenerator (rescale = 1./255, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True)\n",
        "train_generator = train_datagen.flow(x_train, y_train,batch_size = 64)\n",
        "\n",
        "#testing\n",
        "test_model(model5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/80\n",
            "625/625 [==============================] - 466s 746ms/step - loss: 1.9261 - acc: 0.3463 - val_loss: 1.4633 - val_acc: 0.4774\n",
            "Epoch 2/80\n",
            "625/625 [==============================] - 460s 737ms/step - loss: 1.5202 - acc: 0.4510 - val_loss: 1.3042 - val_acc: 0.5323\n",
            "Epoch 3/80\n",
            "625/625 [==============================] - 463s 740ms/step - loss: 1.3990 - acc: 0.4940 - val_loss: 1.2695 - val_acc: 0.5407\n",
            "Epoch 4/80\n",
            "625/625 [==============================] - 462s 740ms/step - loss: 1.2960 - acc: 0.5312 - val_loss: 1.2201 - val_acc: 0.5664\n",
            "Epoch 5/80\n",
            "625/625 [==============================] - 463s 740ms/step - loss: 1.2254 - acc: 0.5599 - val_loss: 1.1409 - val_acc: 0.5962\n",
            "Epoch 6/80\n",
            "625/625 [==============================] - 463s 740ms/step - loss: 1.1630 - acc: 0.5837 - val_loss: 1.2439 - val_acc: 0.5578\n",
            "Epoch 7/80\n",
            "625/625 [==============================] - 463s 741ms/step - loss: 1.1108 - acc: 0.6063 - val_loss: 1.0326 - val_acc: 0.6357\n",
            "Epoch 8/80\n",
            "625/625 [==============================] - 466s 745ms/step - loss: 1.0685 - acc: 0.6182 - val_loss: 1.1694 - val_acc: 0.5970\n",
            "Epoch 9/80\n",
            "625/625 [==============================] - 465s 743ms/step - loss: 1.0369 - acc: 0.6314 - val_loss: 0.9627 - val_acc: 0.6598\n",
            "Epoch 10/80\n",
            "625/625 [==============================] - 464s 743ms/step - loss: 1.0021 - acc: 0.6434 - val_loss: 0.8920 - val_acc: 0.6855\n",
            "Epoch 11/80\n",
            "625/625 [==============================] - 467s 747ms/step - loss: 0.9763 - acc: 0.6524 - val_loss: 0.8937 - val_acc: 0.6868\n",
            "Epoch 12/80\n",
            "625/625 [==============================] - 464s 742ms/step - loss: 0.9481 - acc: 0.6611 - val_loss: 0.9532 - val_acc: 0.6679\n",
            "Epoch 13/80\n",
            "625/625 [==============================] - 462s 739ms/step - loss: 0.9275 - acc: 0.6717 - val_loss: 1.0300 - val_acc: 0.6562\n",
            "Epoch 14/80\n",
            "625/625 [==============================] - 463s 741ms/step - loss: 0.9126 - acc: 0.6762 - val_loss: 0.8930 - val_acc: 0.6888\n",
            "Epoch 15/80\n",
            "625/625 [==============================] - 463s 741ms/step - loss: 0.8863 - acc: 0.6855 - val_loss: 0.8121 - val_acc: 0.7113\n",
            "Epoch 16/80\n",
            "625/625 [==============================] - 466s 745ms/step - loss: 0.8744 - acc: 0.6906 - val_loss: 0.7850 - val_acc: 0.7211\n",
            "Epoch 17/80\n",
            "625/625 [==============================] - 463s 741ms/step - loss: 0.8529 - acc: 0.6974 - val_loss: 0.8097 - val_acc: 0.7128\n",
            "Epoch 18/80\n",
            "625/625 [==============================] - 466s 745ms/step - loss: 0.8380 - acc: 0.7052 - val_loss: 0.8704 - val_acc: 0.7018\n",
            "Epoch 19/80\n",
            "625/625 [==============================] - 464s 743ms/step - loss: 0.8258 - acc: 0.7098 - val_loss: 0.7847 - val_acc: 0.7266\n",
            "Epoch 20/80\n",
            "625/625 [==============================] - 461s 738ms/step - loss: 0.8101 - acc: 0.7144 - val_loss: 0.7947 - val_acc: 0.7199\n",
            "Epoch 21/80\n",
            "625/625 [==============================] - 462s 739ms/step - loss: 0.8035 - acc: 0.7165 - val_loss: 0.9135 - val_acc: 0.6868\n",
            "Epoch 22/80\n",
            "625/625 [==============================] - 465s 744ms/step - loss: 0.7930 - acc: 0.7212 - val_loss: 0.7678 - val_acc: 0.7309\n",
            "Epoch 23/80\n",
            "625/625 [==============================] - 463s 741ms/step - loss: 0.7813 - acc: 0.7269 - val_loss: 0.7928 - val_acc: 0.7275\n",
            "Epoch 24/80\n",
            "625/625 [==============================] - 462s 739ms/step - loss: 0.7635 - acc: 0.7316 - val_loss: 0.7757 - val_acc: 0.7282\n",
            "Epoch 25/80\n",
            "625/625 [==============================] - 460s 737ms/step - loss: 0.7601 - acc: 0.7329 - val_loss: 0.7038 - val_acc: 0.7511\n",
            "Epoch 26/80\n",
            "625/625 [==============================] - 465s 744ms/step - loss: 0.7520 - acc: 0.7363 - val_loss: 0.7614 - val_acc: 0.7330\n",
            "Epoch 27/80\n",
            "625/625 [==============================] - 464s 743ms/step - loss: 0.7383 - acc: 0.7426 - val_loss: 0.7104 - val_acc: 0.7517\n",
            "Epoch 28/80\n",
            "625/625 [==============================] - 461s 738ms/step - loss: 0.7308 - acc: 0.7441 - val_loss: 0.6722 - val_acc: 0.7609\n",
            "Epoch 29/80\n",
            "625/625 [==============================] - 464s 743ms/step - loss: 0.7253 - acc: 0.7468 - val_loss: 0.6448 - val_acc: 0.7692\n",
            "Epoch 30/80\n",
            "625/625 [==============================] - 465s 743ms/step - loss: 0.7203 - acc: 0.7477 - val_loss: 0.6914 - val_acc: 0.7568\n",
            "Epoch 31/80\n",
            "625/625 [==============================] - 465s 744ms/step - loss: 0.7109 - acc: 0.7528 - val_loss: 0.6832 - val_acc: 0.7605\n",
            "Epoch 32/80\n",
            "625/625 [==============================] - 461s 738ms/step - loss: 0.7012 - acc: 0.7544 - val_loss: 0.6607 - val_acc: 0.7681\n",
            "Epoch 33/80\n",
            "625/625 [==============================] - 463s 741ms/step - loss: 0.6986 - acc: 0.7556 - val_loss: 0.6451 - val_acc: 0.7709\n",
            "Epoch 34/80\n",
            "625/625 [==============================] - 466s 746ms/step - loss: 0.6907 - acc: 0.7565 - val_loss: 0.6376 - val_acc: 0.7737\n",
            "Epoch 35/80\n",
            "625/625 [==============================] - 464s 742ms/step - loss: 0.6831 - acc: 0.7618 - val_loss: 0.7271 - val_acc: 0.7506\n",
            "Epoch 36/80\n",
            "625/625 [==============================] - 461s 737ms/step - loss: 0.6743 - acc: 0.7638 - val_loss: 0.6416 - val_acc: 0.7787\n",
            "Epoch 37/80\n",
            "625/625 [==============================] - 466s 745ms/step - loss: 0.6756 - acc: 0.7634 - val_loss: 0.6215 - val_acc: 0.7816\n",
            "Epoch 38/80\n",
            "625/625 [==============================] - 466s 746ms/step - loss: 0.6670 - acc: 0.7677 - val_loss: 0.7270 - val_acc: 0.7522\n",
            "Epoch 39/80\n",
            "625/625 [==============================] - 465s 743ms/step - loss: 0.6539 - acc: 0.7695 - val_loss: 0.6749 - val_acc: 0.7648\n",
            "Epoch 40/80\n",
            "625/625 [==============================] - 462s 740ms/step - loss: 0.6493 - acc: 0.7716 - val_loss: 0.6090 - val_acc: 0.7850\n",
            "Epoch 41/80\n",
            "625/625 [==============================] - 466s 746ms/step - loss: 0.6466 - acc: 0.7752 - val_loss: 0.5944 - val_acc: 0.7907\n",
            "Epoch 42/80\n",
            "625/625 [==============================] - 465s 745ms/step - loss: 0.6449 - acc: 0.7747 - val_loss: 0.6058 - val_acc: 0.7879\n",
            "Epoch 43/80\n",
            "625/625 [==============================] - 466s 746ms/step - loss: 0.6333 - acc: 0.7787 - val_loss: 0.6448 - val_acc: 0.7770\n",
            "Epoch 44/80\n",
            "625/625 [==============================] - 464s 743ms/step - loss: 0.6215 - acc: 0.7837 - val_loss: 0.6315 - val_acc: 0.7791\n",
            "Epoch 45/80\n",
            "625/625 [==============================] - 469s 750ms/step - loss: 0.6255 - acc: 0.7810 - val_loss: 0.6363 - val_acc: 0.7718\n",
            "Epoch 46/80\n",
            "625/625 [==============================] - 467s 747ms/step - loss: 0.6140 - acc: 0.7858 - val_loss: 0.5803 - val_acc: 0.7963\n",
            "Epoch 47/80\n",
            "625/625 [==============================] - 464s 742ms/step - loss: 0.6091 - acc: 0.7867 - val_loss: 0.5908 - val_acc: 0.7915\n",
            "Epoch 48/80\n",
            "625/625 [==============================] - 461s 737ms/step - loss: 0.6105 - acc: 0.7872 - val_loss: 0.5916 - val_acc: 0.7935\n",
            "Epoch 49/80\n",
            "625/625 [==============================] - 465s 744ms/step - loss: 0.6045 - acc: 0.7898 - val_loss: 0.5628 - val_acc: 0.8026\n",
            "Epoch 50/80\n",
            "625/625 [==============================] - 467s 747ms/step - loss: 0.6014 - acc: 0.7902 - val_loss: 0.6220 - val_acc: 0.7874\n",
            "Epoch 51/80\n",
            "625/625 [==============================] - 464s 742ms/step - loss: 0.5972 - acc: 0.7906 - val_loss: 0.5601 - val_acc: 0.8011\n",
            "Epoch 52/80\n",
            "625/625 [==============================] - 464s 742ms/step - loss: 0.5940 - acc: 0.7901 - val_loss: 0.5565 - val_acc: 0.8039\n",
            "Epoch 53/80\n",
            "625/625 [==============================] - 468s 748ms/step - loss: 0.5829 - acc: 0.7962 - val_loss: 0.5666 - val_acc: 0.8032\n",
            "Epoch 54/80\n",
            "625/625 [==============================] - 467s 747ms/step - loss: 0.5728 - acc: 0.8008 - val_loss: 0.5974 - val_acc: 0.7913\n",
            "Epoch 55/80\n",
            "625/625 [==============================] - 464s 743ms/step - loss: 0.5792 - acc: 0.7977 - val_loss: 0.5685 - val_acc: 0.8019\n",
            "Epoch 56/80\n",
            "625/625 [==============================] - 465s 745ms/step - loss: 0.5774 - acc: 0.8009 - val_loss: 0.6214 - val_acc: 0.7847\n",
            "Epoch 57/80\n",
            "625/625 [==============================] - 467s 747ms/step - loss: 0.5630 - acc: 0.8022 - val_loss: 0.5927 - val_acc: 0.7945\n",
            "Epoch 58/80\n",
            "625/625 [==============================] - 467s 748ms/step - loss: 0.5629 - acc: 0.8040 - val_loss: 0.5755 - val_acc: 0.7990\n",
            "Epoch 59/80\n",
            "625/625 [==============================] - 464s 742ms/step - loss: 0.5516 - acc: 0.8069 - val_loss: 0.5906 - val_acc: 0.7973\n",
            "Epoch 60/80\n",
            "625/625 [==============================] - 465s 745ms/step - loss: 0.5533 - acc: 0.8072 - val_loss: 0.5674 - val_acc: 0.8028\n",
            "Epoch 61/80\n",
            "625/625 [==============================] - 467s 747ms/step - loss: 0.5520 - acc: 0.8084 - val_loss: 0.5571 - val_acc: 0.8056\n",
            "Epoch 62/80\n",
            "625/625 [==============================] - 465s 744ms/step - loss: 0.5467 - acc: 0.8087 - val_loss: 0.5554 - val_acc: 0.8042\n",
            "Epoch 63/80\n",
            "625/625 [==============================] - 463s 741ms/step - loss: 0.5467 - acc: 0.8089 - val_loss: 0.5703 - val_acc: 0.8005\n",
            "Epoch 64/80\n",
            "625/625 [==============================] - 465s 744ms/step - loss: 0.5410 - acc: 0.8110 - val_loss: 0.6013 - val_acc: 0.7941\n",
            "Epoch 65/80\n",
            "625/625 [==============================] - 468s 749ms/step - loss: 0.5366 - acc: 0.8130 - val_loss: 0.5263 - val_acc: 0.8144\n",
            "Epoch 66/80\n",
            "625/625 [==============================] - 469s 751ms/step - loss: 0.5371 - acc: 0.8124 - val_loss: 0.5481 - val_acc: 0.8126\n",
            "Epoch 67/80\n",
            "625/625 [==============================] - 467s 747ms/step - loss: 0.5341 - acc: 0.8125 - val_loss: 0.5263 - val_acc: 0.8170\n",
            "Epoch 68/80\n",
            "625/625 [==============================] - 477s 763ms/step - loss: 0.5271 - acc: 0.8165 - val_loss: 0.6009 - val_acc: 0.7920\n",
            "Epoch 69/80\n",
            "625/625 [==============================] - 471s 753ms/step - loss: 0.5256 - acc: 0.8151 - val_loss: 0.5305 - val_acc: 0.8146\n",
            "Epoch 70/80\n",
            "625/625 [==============================] - 469s 751ms/step - loss: 0.5205 - acc: 0.8184 - val_loss: 0.4897 - val_acc: 0.8287\n",
            "Epoch 71/80\n",
            "625/625 [==============================] - 470s 752ms/step - loss: 0.5185 - acc: 0.8187 - val_loss: 0.5114 - val_acc: 0.8226\n",
            "Epoch 72/80\n",
            "625/625 [==============================] - 468s 749ms/step - loss: 0.5112 - acc: 0.8194 - val_loss: 0.5302 - val_acc: 0.8143\n",
            "Epoch 73/80\n",
            "625/625 [==============================] - 469s 751ms/step - loss: 0.5092 - acc: 0.8221 - val_loss: 0.5853 - val_acc: 0.8028\n",
            "Epoch 74/80\n",
            "625/625 [==============================] - 468s 749ms/step - loss: 0.5062 - acc: 0.8210 - val_loss: 0.5171 - val_acc: 0.8213\n",
            "Epoch 75/80\n",
            "625/625 [==============================] - 461s 737ms/step - loss: 0.5108 - acc: 0.8214 - val_loss: 0.4939 - val_acc: 0.8281\n",
            "Epoch 76/80\n",
            "625/625 [==============================] - 466s 745ms/step - loss: 0.5001 - acc: 0.8239 - val_loss: 0.4928 - val_acc: 0.8247\n",
            "Epoch 77/80\n",
            "625/625 [==============================] - 467s 746ms/step - loss: 0.4995 - acc: 0.8245 - val_loss: 0.5132 - val_acc: 0.8210\n",
            "Epoch 78/80\n",
            "625/625 [==============================] - 463s 742ms/step - loss: 0.4976 - acc: 0.8262 - val_loss: 0.4880 - val_acc: 0.8303\n",
            "Epoch 79/80\n",
            "625/625 [==============================] - 461s 738ms/step - loss: 0.4958 - acc: 0.8280 - val_loss: 0.5073 - val_acc: 0.8240\n",
            "Epoch 80/80\n",
            "625/625 [==============================] - 464s 743ms/step - loss: 0.4888 - acc: 0.8313 - val_loss: 0.5256 - val_acc: 0.8172\n",
            "> 81.720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8172"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_QuCAAZzmOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNUsGjuBzmRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhSQH1azzmT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}